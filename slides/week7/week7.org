#+OPTIONS: H:1
#+LATEX_CLASS: beamer
#+COLUMNS: %45ITEM %10BEAMER_env(Env) %10BEAMER_act(Act) %4BEAMER_col(Col) %8BEAMER_opt(Opt)
#+BEAMER_THEME: metropolis
#+BEAMER_COLOR_THEME:
#+BEAMER_FONT_THEME:
#+BEAMER_INNER_THEME:
#+BEAMER_OUTER_THEME:
#+BEAMER_HEADER:


#+LATEX_HEADER: \setbeamertemplate{frame footer}{\insertshortauthor}

#+LATEX_HEADER: \setbeamerfont{page number in head/foot}{size=\tiny}
#+LATEX_HEADER: \setbeamercolor{footline}{fg=gray}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \author{Florian Hollenbach}


#+TITLE: Political Science 209 - Fall 2018
#+SUBTITLE: Linear Regression
#+AUTHOR: Florian Hollenbach
#+DATE: \today
#+EMAIL: fhollenbach@tamu.edu
#+OPTIONS: toc:nil
#+LATEX_HEADER: \usepackage[english]{isodate}
#+LATEX_HEADER: \usepackage{amsmath,amsthm,amssymb,amsfonts}



* Recall Correlation & Scatterplot

#+ATTR_LATEX: :width 6cm
[[~/Documents/GitHub/Polisci209_2018/slides/week7/scatter_cor.pdf]]

*What is the correlation?*

* Recall the definition of correlation

Correlation (x,y) $= \frac{1}{N} \sum^{N}_{i=1}$ z-score of $x_i \times$ z-score of $y_{i}$

Correlation (x,y) $= \frac{1}{N} \sum^{N}_{i=1} \frac{x_{i} - \bar{x}}{sd_{x}} \times   \frac{y_{i} - \bar{y}}{sd_{y}}$


* Correlations & Scatterplots/Data points

1. positive correlation $\rightsquigarrow$ upward slope
2. negative correlation $\rightsquigarrow$ downward slope
3. high correlation $\rightsquigarrow$ tighter, close to a line
4. correlation *cannot* capture nonlinear relationship

* Correlations & Scatterplots/Data points

#+ATTR_LATEX: :width 8cm
[[~/Documents/GitHub/Polisci209_2018/slides/week7/correlations.pdf]]


* Moving from Correlation to Linear Regression

Preview:
- linear regression allows us to create predictions
- linear regression specifies direction of relationship
- linear regression allows us to examine more than two variables at the same time (/statistical control/)

* Linear Regression

- regression has one *dependent (y)* and /for now/ one *independent (x)* variable
- regression is a statistical method to estimate the linear relationship between variables

* Linear Regression

- goal of regression is to approximate the (linear) relationship between X and Y as best as possible
#+BEAMER: \pause
- regression is the mathematical model to draw best fitting line through cloud of points


* Linear Regression

#+ATTR_LATEX: :width 5cm
[[~/Documents/GitHub/Polisci209_2018/slides/week7/scatter_lm.pdf]]

*Linear regression is the mathematical model to draw best fitting line through cloud of points*



* Linear Regression

#+ATTR_LATEX: :width 4cm
[[~/Documents/GitHub/Polisci209_2018/slides/week7/scatter_lm.pdf]]

- regression line is an estimate of the (for now bivariate) relationship between x and y
- for each x we have a prediction of y: *what would we expect y to be given the value of x?*


* What is the equation of a line?

*Equation of a line?*
#+BEAMER: \pause
$y = m  x + b$

$\rightarrow$ b? m?


* What is the equation of a line?

*Equation of a line?*

$y = m  x + b$

b $\rightarrow$ y-intercept

m $\rightarrow$ slope

#+BEAMER: \pause

*regression equation:*

$Y = \alpha + \beta  X + \epsilon$

$\rightarrow$ $\alpha$? $\beta$? $\epsilon$?


* What is the equation of a line?

*Equation of a line?*

$y = m  x + b$

b $\rightarrow$ y-intercept

m $\rightarrow$ slope


*regression equation:*

$Y = alpha + \beta  X + \epsilon$

$\alpha$ $\rightarrow$ y-intercept

$\beta$ $\rightarrow$ slope

$\epsilon$ $\rightarrow$ error


* Regression equation

#+ATTR_LATEX: :width 7cm
[[~/Documents/GitHub/Polisci209_2018/slides/week7/scatter_lm_text.pdf]]



* Regression equation

#+ATTR_LATEX: :width 5cm
[[~/Documents/GitHub/Polisci209_2018/slides/week7/scatter_lm_text.pdf]]

$Y = 282.46 + -26.61  X + \epsilon$



* Regression equation

Model:
  \begin{eqnarray*}
      Y & = & \underbrace{\alpha}_{\textsf{intercept}} +
              \underbrace{\beta}_{\textsf{slope}}  X +
              \underbrace{\epsilon}_{\textsf{error term}} \label{eq:linear.model}
    \end{eqnarray*}

- $Y$: dependent/outcome/response variable
- $X$: independent/explanatory variable, predictor
- $(\alpha, \beta)$: coefficients (parameters of the model)
- $\epsilon$: unobserved error/disturbance term (mean zero)

* Regression: Interpretation of the Parameters:

\begin{eqnarray*}
      Y & = & \underbrace{\alpha}_{\textsf{intercept}} +
              \underbrace{\beta}_{\textsf{slope}}  X +
              \underbrace{\epsilon}_{\textsf{error term}} \label{eq:linear.model}
\end{eqnarray*}

- $\alpha + \beta X$: average of $Y$ at the given the value of $X$
- $\alpha$: the value of $Y$ when $X$ is zero
- $\beta$: increase in $Y$ associated with one unit increase in $X$


* Regression equation

- but, we don't know the equation that generates the data
- our regression line is an estimate, based on the collected data

#+BEAMER: \pause

- estimates are denoted with little hats: $\hat{\beta}$, $\hat{\alpha}$
- $(\hat\alpha, \hat\beta)$: estimated coefficients

#+BEAMER: \pause
- we can use $(\hat\alpha, \hat\beta, X)$ to create /predicted values/ of y
- $\widehat{Y} = \hat\alpha + \hat\beta x$: predicted/fitted value


* Regression equation

\Large{How far off is our line? How do we know?}


* Regression equation

How far off is our line? How do we know?

#+BEAMER: \pause
$\hat\epsilon = \text{ true } Y - \widehat{Y}$: residuals/error

$\hat\epsilon$'s are an estimate of how good/bad our line approximates the relationship

* Regression

#+ATTR_LATEX: :width 7cm
[[~/Documents/GitHub/Polisci209_2018/slides/week7/scatter_lm_resid.pdf]]



* Regression

- $(\alpha, \beta)$ are estimated from the data
- How do we find $\alpha, \beta$?

* Regression: How do we find $\alpha, \beta$?

*We minimize the sum of the squared residuals*

#+ATTR_LATEX: :width 5cm
[[~/Documents/GitHub/Polisci209_2018/slides/week7/wat.png]]



* Regression: How do we find $\alpha, \beta$?

*We minimize the /sum of the squared residuals (SSR)/*

\begin{eqnarray*}
\textsf{SSR} & = & \sum_{i=1}^n \hat\epsilon_i^2
              \ = \ \sum_{i=1}^n (Y_i - \widehat{Y_{i}})^2
              \ = \  \sum_{i=1}^n (Y_i - \hat\alpha - \hat\beta X_i)^2
\end{eqnarray*}

#+BEAMER: \pause

This also minimizes the root mean squared error: RMSE $= \sqrt{\frac{1}{n}\textsf{SSR}}$

* Regression by Hand

\begin{eqnarray*}
  \hat\alpha & = & \bar{Y} - \hat\beta \bar{X} \\
  \hat\beta & = & \frac{\sum_{i=1}^n (Y_i - \overline{Y})(X_i - \overline{X})}{\sum_{i=1}^n (X_i - \overline{X})^2}
    \end{eqnarray*}

OR:
#+BEAMER: \pause
\begin{eqnarray*}
      \hat\beta & = & \textsf{correlation of $X$ and $Y$} \times
                      \frac{\textsf{standard deviation of $Y$}}{\textsf{standard
                      deviation of $X$}}
    \end{eqnarray*}


* Regression by Hand

Regression line always goes through the point of averages ($\hat{X},\hat{Y}$)

\begin{eqnarray*}
   \widehat{Y}  & = & (\overline{Y} - \hat\beta \overline{X}) + \hat\beta \overline{X} \ =
                    \ \overline{Y}
\end{eqnarray*}


* Regression always goes through point of averages

#+ATTR_LATEX: :width 7cm
[[~/Documents/GitHub/Polisci209_2018/slides/week7/scatter_lm_mean.pdf]]


* Regression NOT by Hand

*Enough math!*

Fitting/estimating a regression in /R/:

#+begin_src R :eval no
lm(dependent ~ independent, data = data_object)
#+end_src


* Regression NOT by Hand

*Fitting/estimating a regression in /R/:*

#+begin_src R :eval no
data <- read.csv("bivariate_data.csv")
data <- subset(data, Year ==2010)
result <- lm(Child.Mortality ~ log(GDP) , data = data)
summary(result)
#+end_src


* Regression NOT by Hand

#+begin_src R :results output :exports both :session
result <- lm(Child.Mortality ~ log(GDP) , data = data)
coef(result) ### coefficients
#+end_src

/R/-output:

(Intercept): $\alpha$

/log(GDP)/: $\beta$

* Model Fit

How well does our regression line fit the data?

How well does the model predict the outcome?

#+BEAMER: \pause

$R^{2}$ or /coefficient of determination/:

\begin{eqnarray*}
      R^2 & = & 1 - \frac{\textsf{SSR}}{\textsf{Total sum of squares (TSS)}}  \ = \ 1 - \frac{\sum_{i=1}^n \hat\epsilon_i^2}{\sum_{i=1}^n (Y_i - \overline{Y})^2}
    \end{eqnarray*}

* Model Fit

\begin{eqnarray*}
      R^2 & = & 1 - \frac{\textsf{SSR}}{\textsf{Total sum of squares (TSS)}}  \ = \ 1 - \frac{\sum_{i=1}^n \hat\epsilon_i^2}{\sum_{i=1}^n (Y_i - \overline{Y})^2}
    \end{eqnarray*}

$R^{2}$ is also defined as the /explained variance/ in Y

How much of the deviation of Y from the average is explained by X?



* Model Fit
:PROPERTIES:
    :BEAMER_opt: shrink=15
    :END:

#+begin_src R :results output :exports both :session
result <- lm(Child.Mortality ~ log(GDP) , data = data)
summary(result)
#+end_src
