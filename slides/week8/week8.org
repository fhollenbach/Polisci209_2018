#+OPTIONS: H:1
#+LATEX_CLASS: beamer
#+COLUMNS: %45ITEM %10BEAMER_env(Env) %10BEAMER_act(Act) %4BEAMER_col(Col) %8BEAMER_opt(Opt)
#+BEAMER_THEME: metropolis
#+BEAMER_COLOR_THEME:
#+BEAMER_FONT_THEME:
#+BEAMER_INNER_THEME:
#+BEAMER_OUTER_THEME:
#+BEAMER_HEADER:


#+LATEX_HEADER: \setbeamertemplate{frame footer}{\insertshortauthor}

#+LATEX_HEADER: \setbeamerfont{page number in head/foot}{size=\tiny}
#+LATEX_HEADER: \setbeamercolor{footline}{fg=gray}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \author{Florian Hollenbach}


#+TITLE: Political Science 209 - Fall 2018
#+SUBTITLE: Linear Regression
#+AUTHOR: Florian Hollenbach
#+DATE: \today
#+EMAIL: fhollenbach@tamu.edu
#+OPTIONS: toc:nil
#+LATEX_HEADER: \usepackage[english]{isodate}
#+LATEX_HEADER: \usepackage{amsmath,amsthm,amssymb,amsfonts}



* In-class Exercise Linear Regression

Please dowload /intrade08.csv/ & /pres08.csv/ from class website

- Read both data sets into /R/
- Create data summary for each data sets

* Variables in the intrade data

- /day/: Date of the session
- /statename/: Full name of each state (including District of Columbia in 2008)
- /state/: Abbreviation of each state (including District of Columbia in 2008)
- /PriceD/: Closing price (predicted vote share) of Democratic Nominee's market
- /PriceR/: Closing price (predicted vote share) of Republican Nominee's market
- /VolumeD/: Total session trades of Democratic Party Nominee's market
- /VolumeR/: Total session trades of Republican Party Nominee's market


* Variables in the pres08 data

- /state.name/: Full name of state (only in pres2008)
- /state/: Two letter state abbreviation
- /Obama/: Vote percentage for Obama
- /McCain/: Vote percentage for McCain
- /EV/: Number of electoral college votes for this state

* Combining data sets

- First we have to combine the different data sets
- To do so, we need an identifier that tells /R/ which observations to match to each other
- What could we use?

#+BEAMER: \pause

*state variable*

* Combining data sets

- Use /merge()/ function

#+begin_src R :eval no
merge(x,y, by =)
intresults08 <- merge(intrade08, pres08, by = "state")
head(intresults08)
#+end_src


* Question 1


Create a /DaysToElection/ variable by subtracting the day of the election from each day in the dataset. Now create a /state margin of victory/ variable to predict, and a /betting market margin/ to predict it with.

*election day in 2008: Nov, 4th*

* Solution 1
:PROPERTIES:
    :BEAMER_opt: shrink=20
    :END:


#+begin_src R :eval no
intresults08$DaysToElection
 <- as.Date("2008-11-04") - as.Date(intresults08$day)

intresults08$obama.intmarg <- intresults08$PriceD - intresults08$PriceR
intresults08$obama.actmarg <- intresults08$Obama - intresults08$McCain
#+end_src


* Question 2


Considering only the trading *one day from the election*, predict the actual electoral margins from the trading margins using a linear model. Does it predict well? How would you visualize the predictions and the outcomes together? Hint: because we only have one predictor you can use /abline/.

* Solution 2
:PROPERTIES:
    :BEAMER_opt: shrink=20
    :END:

#+begin_src R :eval no
latest08 <- intresults08[intresults08$DaysToElection == 1,]
int.fit08 <- lm(obama.actmarg ~ obama.intmarg, data = latest08)
coef(int.fit08)
summary(int.fit08)$r.squared
plot(latest08$obama.intmarg, latest08$obama.actmarg,
    xlab="Market's margin for Obama", ylab="Obama margin")
abline(int.fit08)
#+end_src



* Question 3

What would be the prediction for the margin of victory if the InTrade margin was 25? Mark this point on the previous plot.


* Solution 3
:PROPERTIES:
    :BEAMER_opt: shrink=20
    :END:

#+begin_src R :eval no
coef(int.fit08)[1] + coef(int.fit08)[2]*25

plot(latest08$obama.intmarg, latest08$obama.actmarg,
    xlab="Market's margin for Obama", ylab="Obama margin")
abline(int.fit08)
points(25,(coef(int.fit08)[1] + coef(int.fit08)[2]*25), col = "red")
#+end_src




* Question 4
:PROPERTIES:
    :BEAMER_opt: shrink=20
    :END:

Even efficient markets aren’t omniscient. Information comes in about the election every day and the market prices should reflect any change in information that seem to matter to the outcome.

We can examine how and about what the markets change their minds by looking at which states they are confident about, and which they update their ‘opinions’ (i.e. their prices) about. Over the period before the election, let’s see how prices for each state are evolving. We can get a compact summary of price movement by fitting a linear model to Obama’s margin for each state over the 20 days before the election.

We will summarise price movement by the direction (up or down) and rate of change (large or small) of price over time. This is basically also what people in finance do, but they get paid more…

*Start by plotting Obama’s margin in West Virginia against the number of days until the election and modeling the relationship with a linear model. Use the last 20 days. Show the model's predictions on each day and the data. What does this model's slope coefficient tells us about which direction the margin is changing and also how fast it is changing?*


* Solution 4
:PROPERTIES:
    :BEAMER_opt: shrink=20
    :END:

#+begin_src R :eval no
stnames <- unique(intresults08$state.name)
recent <- subset(intresults08, subset=(DaysToElection <= 20)
 & (state.name==stnames[1]))

recent.mod <- lm(obama.intmarg ~ DaysToElection, data=recent)
plot(recent$DaysToElection, recent$obama.intmarg,
xlab="Days to election", ylab="Market's Obama margin")
abline(recent.mod)
#+end_src

* Question 5

Let's do the same thing for all states and collect the slope coefficients ($\beta$'s). How can we modify the code from the answer to the previous question? Then plot the distribution of changes for all states.

* Solution 5
:PROPERTIES:
    :BEAMER_opt: shrink=25
    :END:

#+begin_src R :eval no
stnames <- unique(intresults08$state.name)
change <- rep(NA, length(unique(intresults08$state.name)))
names(change) <- unique(intresults08$state.name)

for(i in 1: length(unique(intresults08$state.name))){
recent <- subset(intresults08, subset=(DaysToElection <= 20)
& (state.name==stnames[i]))

recent.mod <- lm(obama.intmarg ~ DaysToElection, data=recent)
change[i] <- coef(recent.mod)[2]
}
hist(change)
#+end_src


* Questin 5

Estimate a linear model using the intrade margin in the average intrade margin in the week before the election to predict vote margin in 2008. How well does the model predict?

* Solution 5
:PROPERTIES:
    :BEAMER_opt: shrink=25
    :END:


#+begin_src R :eval no
latest08 <- intresults08[intresults08$DaysToElection <8,]
average.Intrade <- tapply(latest08$obama.intmarg, latest08$state, mean)
true.margin <- tapply(latest08$obama.actmarg, latest08$state, mean)

int.fit08 <- lm(true.margin ~ average.Intrade)
coef(int.fit08)
summary(int.fit08)$r.squared

#+end_src

* Question 6

Next, we read in the same data for the 2012 election. Use the linear model created above to create predictions for the margin in 2012. Calculate and plot the prediction error.

* Solution 6
:PROPERTIES:
    :BEAMER_opt: shrink=25
    :END:


#+begin_src R :eval no
data2012 <- read.csv("intresults12.csv")
data2012$DaysToElection <- as.Date("2008-11-06") - as.Date(data2012$day)
data2012$obama.intmarg <- data2012$PriceD - data2012$PriceR
data2012$obama.actmarg <- data2012$Obama - data2012$Romney
#+end_src


* Solution 6
:PROPERTIES:
    :BEAMER_opt: shrink=25
    :END:


#+begin_src R :eval no
latest12
<- data2012[data2012$DaysToElection <8,]

average.Intrade12
<- tapply(latest12$obama.intmarg, latest12$state, mean, na.rm = T)

true.margin12
<- tapply(latest12$obama.actmarg, latest12$state, mean, na.rm = T)

prediction
<- coef(int.fit08)[1] + coef(int.fit08)[2]*average.Intrade12

error <- true.margin12 - prediction
hist(error)
#+end_src


* Linear Regression and RCTs

Can we estimate regression models on data from experiments?

#+BEAMER: \pause

*Yes, treatment status as the independent variable (0 or 1)*


* Linear Regression and RCTs

-  y = \alpha + \beta * treatment + \epsilon

- \beta = average treatment effect

- The two predicted values are the average outcome under each condition

#+BEAMER: \pause

- \beta: Predicted change in Y /caused/ by increase of /T/ by 1

#+BEAMER: \pause

*Remember, generally regression coefficents are not to be interpreted as causal effects!*




* Linear Regression with multiple independent variables

\begin{eqnarray*}
      Y & = & \alpha + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_p X_p + \epsilon
\end{eqnarray*}

- principle of regression model stays the same

- we attempt to draw the best fitting line through a cloud of points (now in multiple dimensions)

*  Linear Regression with multiple independent variables

We still minimize the sum of the squared residuals:

\begin{eqnarray*}
      \textsf{SSR} & = & \sum_{i=1}^n \hat\epsilon_i^2
    \end{eqnarray*}


*  Linear Regression with multiple independent variables

We still minimize the sum of the squared residuals:

\begin{eqnarray*}
      \textsf{SSR} & = & \sum_{i=1}^n \hat\epsilon_i^2 \ = \ \sum_{i=1}^n
                         (Y_i - \hat{Y})^2
    \end{eqnarray*}


*  Linear Regression with multiple independent variables

We still minimize the sum of the squared residuals:


\begin{eqnarray*}
      \textsf{SSR} & = & \sum_{i=1}^n \hat\epsilon_i^2 \ = \ \sum_{i=1}^n
                         (Y_i - \hat{Y})^2
    \end{eqnarray*}

And thus:

\begin{eqnarray*}

 \textsf{SSR} &=& \sum_{i=1}^n (Y_i - (\hat\alpha + \hat\beta_1 X_{i1} +
                         \hat\beta_2 X_{i2} + \cdots + \hat\beta_p X_{ip}))^2
    \end{eqnarray*}



*  Linear Regression with multiple independent variables

Interpretation:

- $\alpha$: Intercept or $\hat{y}$ when all $X_{p} = 0$

#+BEAMER: \pause

- $\beta_{p}$: Slope of predictor $X_{p}$

#+BEAMER: \pause

- $\beta_{p}$: Predicted change in $\hat{Y}$ when $X_{p}$ increases by $1$ *and* all other predictors *are held constant*!



*  Linear Regression with multiple independent variables

- $\beta_{p}$: Predicted change in $\hat{Y}$ when $X_{p}$ increases by $1$ *and* all other predictors *are held constant*!

- we can use the multiple regression to *control for confounders*

#+BEAMER: \pause

- impact of each individual predictor when the other predictors do not change

- Example: Association between income and child mortality when regime type is not changing

*  Linear Regression with multiple independent variables in /R/


#+begin_src R :eval no
result <- lm(y ~ x1 + x2 + x3 + x4, data = data)
coef(result)
#+end_src



*  Linear Regression with multiple independent variables in /R/


#+begin_src R :eval no
data <- read.csv("bivariate_data.csv")
data2010 <- subset(data, Year == 2010)
bivar <- lm(Child.Mortality ~ log(GDP), data = data)
coef(bivar)
summary(bivar)$r.squared
#+end_src

*  Linear Regression with multiple independent variables in /R/



#+begin_src R :results output :exports both :session
data <- read.csv("bivariate_data.csv")
data2010 <- subset(data, Year == 2010)
bivar <- lm(Child.Mortality ~ log(GDP), data = data2010)
coef(bivar)
summary(bivar)$r.squared
#+end_src




*  Linear Regression with multiple independent variables in /R/
:PROPERTIES:
    :BEAMER_opt: shrink=20
    :END:


#+begin_src R :eval no
data <- read.csv("bivariate_data.csv")
data2010 <- subset(data, Year == 2010)
multiple <- lm(Child.Mortality ~ log(GDP) + PolityIV, data = data2010)
coef(multiple)
summary(multiple)$r.squared
#+end_src



*  Linear Regression with multiple independent variables in /R/
:PROPERTIES:
    :BEAMER_opt: shrink=20
    :END:


#+begin_src R :results output :exports both :session
data <- read.csv("bivariate_data.csv")
data2010 <- subset(data, Year == 2010)
multiple <- lm(Child.Mortality ~ log(GDP) + PolityIV, data = data2010)
coef(multiple)
summary(multiple)$r.squared
#+end_src



*  Linear Regression with multiple independent variables in /R/
:PROPERTIES:
    :BEAMER_opt: shrink=20
    :END:


#+begin_src R :results output :exports both :session
data <- read.csv("bivariate_data.csv")
data2010 <- subset(data, Year == 2010)
multiple <- lm(Child.Mortality ~ log(GDP) + PolityIV, data = data2010)
coef(multiple)
coef(bivar)
#+end_src


*  Linear Regression with multiple independent variables in /R/

- In multiple regression models we want to adjust the goodness of fit statistic by the number of variables included
- This is done via the degrees of freedom (DF) adjustment:

\begin{eqnarray*}
      \textsf{adjusted} R^{2} & = & 1 - \frac{SSR /(n-p-1)}{TSS/(n-1)}
    \end{eqnarray*}

*  Linear Regression with multiple independent variables in /R/
:PROPERTIES:
    :BEAMER_opt: shrink=20
    :END:

#+begin_src R :eval no
data <- read.csv("bivariate_data.csv")
data2010 <- subset(data, Year == 2010)
multiple <- lm(Child.Mortality ~ log(GDP) + PolityIV, data = data2010)
coef(multiple)
summary(multiple)$r.squared
summary(multiple)$adj.r.squared
#+end_src

*  Linear Regression with multiple independent variables in /R/
:PROPERTIES:
    :BEAMER_opt: shrink=20
    :END:

#+begin_src R :results output :exports both :session
data <- read.csv("bivariate_data.csv")
data2010 <- subset(data, Year == 2010)
multiple <- lm(Child.Mortality ~ log(GDP) + PolityIV, data = data2010)
coef(multiple)
summary(multiple)$r.squared
summary(multiple)$adj.r.squared
#+end_src
